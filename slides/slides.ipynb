{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "8076ada7-3a74-4d92-bc0f-02bcb6502085"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1830f06d-b310-4146-afda-9da714b941c7"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi-view 3D Ultrasound Fusion for  Complete Fetal Head Reconstruction\n",
    "\n",
    "* Ultrasound images suffer from artefacts which limit its diagnostic value, notably acoustic shadow.\n",
    "\n",
    "* Shadows are dependent on probe orientation, with each view giving a distinct, partial view of the anatomy.\n",
    "\n",
    "* We fuse the partially imaged fetal head anatomy, acquired from many views (hundreds), into a single coherent compounding of the full anatomy.\n",
    "\n",
    "<img width=\"100%\" src=\"head-fusion-illustration.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example of 3D ultrasound stream input data\n",
    "\n",
    "<br>\n",
    "<video width=\"80%\" src=\"pose-uncorrected.mp4\" controls autoplay loop autopause mute></video>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image artifacts confound interpretation\n",
    "\n",
    "* namely - shadow, speckle, anisotropic resolution\n",
    "\n",
    "<img width=\"80%\" src=\"artifacts.svg\"> \n",
    "\n",
    "[//]: # (also refractive distortion, attenuation)\n",
    "[//]: # (typically caused by refraction or strong reflector differences in acoustic impedance between tissues, like bone interfaces, create hadows that obscure the anatomy behind.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# View dependent modality\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "    <div class=\"column\" style=\"width:60%;object-fit:cover;\">\n",
    "<ul><li>no single 3D representation of the anatomy unlike CT / MRI </li>\n",
    "<li>each anatomical structure is best visualised from a particular probe orientation, typically where tissues interfaces are perpendicular to the US beam.</li></ul>\n",
    "    <img width=\"95%\" src=\"views-of-fetal-head.svg\"> \n",
    "    </div>\n",
    "    <div class=\"column\" style=\"width:40%;object-fit:cover;\">\n",
    "        <ul><li>resolution varies across the volume\n",
    "            <li>beam can be focussed</li>\n",
    "        </ul>\n",
    "        <img width=\"95%\" src=\"US-resolutin.jpg\"> \n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "[//]: # (TODO add face view, side view etc)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Current screening practice\n",
    " \n",
    "<div class=\"bgimgclass\" style=\"height:100%\">\n",
    "    <div class=\"row\">\n",
    "        <div class=\"column\" style=\"width:50%;object-fit:cover;\">\n",
    "<br>            \n",
    "<ul>\n",
    "<li> predominantly 2D\n",
    "     <ul><li> faster acquisition, increased resolution</li> \n",
    "</ul>\n",
    "<li> navigate to standard anatomical plane, take biometric measurement </li>\n",
    "<li> takes training and expertise to navigate and recognise anomalies </li>\n",
    "<li> limits assessment of 3D shape / structure </li>\n",
    "</ul>\n",
    "<br>\n",
    "        <img width=\"80%\" src=\"bpd.jpg\"> \n",
    "        </div>\n",
    "        <div class=\"column\" style=\"width:50%\">\n",
    "            <img width=\"80%\" src=\"screening.png\"> \n",
    "            <img width=\"80%\" src=\"Biparietal_diameter_by_gestational_age.png\"> \n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image fusion to the rescue!\n",
    "\n",
    "* Automatic alignment and fusion of images could\n",
    "    - remove view dependency\n",
    "        - ie provide a single 3D representation of the anatomy\n",
    "    - improve image quality\n",
    "    - make images easier to interpret\n",
    "    - no requirement to navigate standard planes\n",
    "        - reduce skill/training needed\n",
    "    - improve diagnosis\n",
    "    - image analysis of 3D anatomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Complimentary to 2D ultrasound exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "54882ef8-0656-46a9-acb1-dbea465af9e3"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is image fusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Combine all the information from multiple images to produce a single more informative image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Surpass limits of our sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Fused image may be\n",
    "    * more accurate\n",
    "    * more detailed\n",
    "    * larger field of view\n",
    "    * better optimised for human perception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi-focus image fusion\n",
    "\n",
    "* Preserve high frequency detail from each image\n",
    "\n",
    "<img width=\"100%\" src=\"Sample_of_Multi-Focus_image_fusion.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi-exposure image fusion\n",
    "* increase dynamic range\n",
    "\n",
    "<img width=\"50%\" src=\"HDRI-Example.jpg\">\n",
    "<img width=\"60%\" src=\"Old_saint_pauls_1.jpg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stitching / mosaicing - extending FOV\n",
    "<img width=\"100%\" src=\"Fenway_Park.jpg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multi-modality fusion\n",
    "\n",
    "* Combine complimentary information\n",
    "    * Low resolution PET scan showing metabolic information\n",
    "    * High resolution MR showing anatomy\n",
    "    \n",
    "<img width=\"100%\" src=\"pet-mri.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Goals for fetal head ultrasound fusion\n",
    "\n",
    "* Eliminate speckle\n",
    "    * increase signal-to-noise ratio\n",
    "* Eliminate shadows\n",
    "* Preserve features at highest resolution\n",
    "* Increase field of view to whole head at later gestation\n",
    "* View independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Laplacian pyramid - for multi-scale fusion\n",
    "\n",
    "* Bandpass filter - localise features in space and in frequency\n",
    "* Reversible process\n",
    "* Super fast to compute on GPU (10ms, with pytorch)\n",
    "\n",
    "<img width=\"80%\" src=\"laplacian_pyramid.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "83bf86ab-0d57-42a4-840b-beffb416934e"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fusing $n$ image pyramids\n",
    "\n",
    "* independent fusion of features at each scale - via weighted average\n",
    "\n",
    "$P^{j}=(L_{0}^{j},\\,L_{1}^{j}\\,,L_{2}^{j}\\,,I_{2}^{j}\\,)$ - pyramid for the $j$th image.\n",
    "\n",
    "$\\bar{P}=(\\bar{L_{0}},\\,\\bar{L_{1}}\\,,\\bar{L_{2}}\\,,\\bar{I_{2}}\\,)$ - average pyramid\n",
    "\n",
    "$\\bar{L_{i}}=\\sum_{j=1}^{n}W_{i}^{j}\\circ L_{i}^{j}$. \n",
    "\n",
    "$\\bar{I_{2}}=\\sum_{j=1}^{n}W_{2}^{j}\\circ I_{2}^{j}$.\n",
    "\n",
    "\n",
    "$W_{i}^{j}$ - voxel weight map\n",
    "\n",
    "$\\circ$ - element-wise multiplication\n",
    "\n",
    "[//]: # (TODO show example for 2 images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Saliency-based weighting\n",
    "\n",
    "* A simple average of the aligned images, results in a suboptimal fusion, where the most detailed image features are degraded.\n",
    "\n",
    "* Select and average only the best (salient) image features from a subset of images in order to maximise information content.\n",
    "\n",
    "* Difference images provide an edge-detection map for free!\n",
    "\n",
    "* Upweight strong (salient) edges\n",
    "\n",
    "$W_{i}^{j}(x)=|L_{i}^{j}(x)|\\;\\forall x$.\n",
    "<br>\n",
    "$x$ - voxel index\n",
    "\n",
    "\n",
    "[//]: # (TODO show saliency image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Saliency fusion is easily corrupted\n",
    "<br>\n",
    "<img width=\"70%\" src=\"misaligned-registrations-without-proposed.svg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fudge compromise - tune saliency weighting with $\\alpha$ \n",
    "\n",
    "Exponentiating weight maps allows control of saliency weighting.\n",
    "\n",
    "$W(x)^{\\alpha}\\;\\forall x$\n",
    "<br>\n",
    "\n",
    "* $\\uparrow\\alpha$\n",
    "    * sharper fusion but more artefacts\n",
    "    * reduced SNR (a subset of images with strong edges will dominate).\n",
    "\n",
    "* $\\alpha = 0$\n",
    "    * reduces to mean of all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature consistency - a better approach\n",
    "\n",
    "* Replace fixed alpha with a voxel-wise feature consistency map.\n",
    "    * automatically control influence of saliency\n",
    "* Compare each image to a fusion of all other images\n",
    "    * compute local cross correlation (LNCC)\n",
    "    * downweight dissimilar regions\n",
    "\n",
    "\n",
    "$C_{i}^{j}=\\textrm{LNCC}(I_{i}^{j},\\,\\hat{I}_{i}^{j})$\n",
    "\n",
    "$\\hat{I}_{0}^{j}$ - fusion of all images except $j$\n",
    "\n",
    "\n",
    "$\\hat{I}_{1}^{j}$, $\\hat{I}_{2}^{j}$ are downsampled fusions\n",
    "\n",
    "\n",
    "$\\begin{array}{c}\n",
    "\\bar{L_{i}}=\\sum_{j=1}^{n}\\textrm{pow}(W_{i}^{j},\\alpha\\,C_{i}^{j}\\circ\\bar{C}_{i})\\circ L_{i}^{j},\\\\\n",
    "\\bar{I_{2}}=\\sum_{j=1}^{n}\\textrm{pow}(W_{2}^{j},\\alpha\\,C_{2}^{j}\\circ\\bar{C}_{2})\\circ I_{2}^{j}.\n",
    "\\end{array}$\n",
    "\n",
    "$\\bar{C}_{i}=\\frac{1}{n}\\sum_{j=1}^{n}C_{i}^{j}$ - mean consistency map - allows greater smoothing to be applied in highly inconsistent regions across all images, such as outside of the head.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature consistency fusion is robust\n",
    "\n",
    "<img width=\"75%\" src=\"misaligned-registrations-consistency.svg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "96643c64-2976-4c4b-9735-6ade96774338"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image alignment is critical to image fusion quality!\n",
    "\n",
    "* Poorly aligned images introduce blurriness and may even distort the correct geometric relationship between anatomical structures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previous methods - 1D chain of temporal neighbours \n",
    "\n",
    "* Slow, smooth sweeping motions to acquire data.\n",
    "* Temporal neighbours assumed to be well initialised for registration\n",
    "    * with sufficient overlap\n",
    "* Scene is assumed to be static   \n",
    "* Estimate correspondences between frames using similarity-based registration\n",
    "\n",
    "<img width=\"75%\" src=\"s-acquisition.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previous methods - fusion approaches\n",
    "1. Align on the fly \n",
    "    * register each new frame to lastest fused representation\n",
    "\n",
    "2. Refine iteratively offline\n",
    "    * estimate local transformations between temporal neighbours\n",
    "    * optimise global transformations to fusion space, by minimising local transformation errors\n",
    "    * infer new neighbours in fusion space\n",
    "    \n",
    "<img width=\"85%\" src=\"topology-refinement.svg\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Challenges for aligning 4D fetal US streams \n",
    "\n",
    "* Fetal movement, lost probe contact, fast probe movement / angulation\n",
    "    * temporally adjacent frames are often not well initialised for registration\n",
    "    \n",
    "* Heterogeneous appearance - dependent on view\n",
    "    - voxel-based similarity measures are ill-suited\n",
    "        - even robust alignment techniques will fail. e.g block- matching\n",
    "    - could transform to view-independent domain, e.g extract surface models of the head (Khanal, 2018).\n",
    " \n",
    "* Previous methods are not robust enough for fetal imaging\n",
    "    * a single failed registration can cause misalignment of all subsequent frames!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# New approach - direct pose estimation\n",
    "\n",
    "* Directly estimate transformation of anatomy to canonical pose / fusion space.\n",
    "\n",
    "* Register each frame independently - break dependence on fragile chain of pairwise registrations\n",
    "\n",
    "* Allows alignment of many more images than previous state-of-the-art (hundreds or thousands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Direct pose estimation\n",
    "\n",
    "Original stream\n",
    "<video width=\"80%\" src=\"pose-uncorrected.mp4\" controls autoplay loop autopause mute></video>\n",
    "\n",
    "Pose corrected stream\n",
    "<video width=\"80%\" src=\"stream-pose-correction.mp4\" controls autoplay loop autopause mute></video>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LSTM spatial transformer network\n",
    "\n",
    "* Advantages of iterative approach\n",
    "    * better performance with much reduced network capacity\n",
    "        * less overfitting\n",
    "    * exploit long term rewards, develop a robust strategy\n",
    "        * take the easiest route / not shortest\n",
    "        * rubik's cube analogy\n",
    "    * allows finer alignment\n",
    "    \n",
    "<img width=\"150%\" src=\"pose-correction.svg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Based on previous work for US-MR fetal brain registration\n",
    "\n",
    "Wright et al., LSTM Spatial Co-transformer Networks for Registration of 3D Fetal US and MR Brain Images (MICCAI 2018)\n",
    "\n",
    "<div class=\"bgimgclass\" style=\"height:100%\">\n",
    "    <div class=\"row\">\n",
    "        <div class=\"column\" style=\"width:50%;object-fit:cover;\">\n",
    "            <video width=\"100%\" src=\"registration.mp4\" controls autoplay loop autopause mute></video>\n",
    "        </div>\n",
    "        <div class=\"column\" style=\"width:50%\">\n",
    "            <ul>\n",
    "                <li> Supervised - training data aligned to spatio-temporal atlas template </li>\n",
    "                <li> Robust - can register image pairs with any initial orientation, and large translations (up to 50mm) </li> \n",
    "                <li> Accuracy is the same regardless of initialisation </li> \n",
    "                <li> Mean translation error ~ 0.6mm </li> \n",
    "                <li> Mean rotation error ~ 2.9 degrees </li> \n",
    "           </ul> \n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Complete pipeline for fetal head reconstruction\n",
    "\n",
    "* Last step - can refine alignment (& fusion) by iteratively registering images to current fused representation using block matching.\n",
    "\n",
    "<img width=\"75%\" src=\"overview.svg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f357ecfe-ee26-41a6-a9fa-07edc8c6b7f5"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparison of fused images\n",
    "\n",
    "<img width=\"75%\" src=\"compoundings.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applications - Faster screening for facial abnormality\n",
    "\n",
    "* 1 minute to acquire 240 images for our method vs 10 minutes for an expert sonographer to find a good view of the face.\n",
    "\n",
    "* Face is often obscured by the limbs or maternal tissue, thus acquiring a satisfactory view may be not be possible, especially when the fetus is moving frequently.\n",
    "\n",
    "* Pose corrected, fused volume is easily masked e.g. via atlas-based segmentation.\n",
    "\n",
    "<img width=\"75%\" src=\"head-shot-clinic.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Faster screening for facial abnormality\n",
    "\n",
    "<img width=\"100%\" src=\"head-renderings.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Easier interpretation of skull development\n",
    "\n",
    "* Premature fusion of cranial sutures results in abnormal cranial shape and increased risk for cognitive disabilities.\n",
    "\n",
    "* Navigating to the optimal view to visualise a single suture is difficult and time consuming, especially when the fetus is moving.\n",
    "\n",
    "* Our method allows easy interpretation of head shape and sutures through manipulation of a 3D model.\n",
    "\n",
    "<img width=\"100%\" src=\"sutures2.svg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Low cost alternative to MRI for neurodevelopmental assessment\n",
    "\n",
    "* Multi-view fusion has fewer artefacts compared with single-view images, which allows easier application of image analysis methods for registration and segmentation, etc.\n",
    "* Could lead to low cost automated 3D biometrics in the future.\n",
    "<img width=\"80%\" src=\"mr-vs-us.svg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problems / Future work \n",
    "\n",
    "## Sonographic feedback\n",
    "\n",
    "* Deployment requires real-time feedback of views acquired\n",
    "    - sonographers are scanning blind\n",
    "    - guarantee full coverage \n",
    "    - speed up acquisition\n",
    "    \n",
    "\n",
    "* currently exploring options such as real-time volume rendering\n",
    "\n",
    "<video width=\"80%\" src=\"on-the-fly-compounding.mp4\" controls autoplay loop autopause mute></video>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
